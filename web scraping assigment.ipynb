{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46daea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data\n",
    "\n",
    "\n",
    "\"\"\"web scraping is a technique of extracting data from website using automated softwear or tools .\n",
    "it involves collicting data from web pages and converting it into structured format for\n",
    "analysis and future use\"\"\"\n",
    "\n",
    "#web scraping used for various purposes,including:-\n",
    "#1 market research\n",
    "2# data analysis\n",
    "3# lead generation\n",
    "\n",
    "#here some areas where web scraping is used to  get data are:-\n",
    "#1 E-commerce\n",
    "#2 social media\n",
    "#3 real estate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b6a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0168f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "#thare are some has some method for web scraping:-\n",
    "#1 parsing html- like beautiful soup\n",
    "#2 web scraping tools- like ParseHub. scrapy\n",
    "#3 using APIs-Some websites provide APIs (Application Programming Interfaces) that allow developers to access and extract data in a structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2b8508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8bea348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What is Beautiful Soup? Why is it used?\n",
    "#Beautiful Soup is a Python package for parsing HTML and XML documentsBeautiful Soup is a Python library that is used for web scraping purposes. It is used to extract data from HTML and XML files.\n",
    "\n",
    "# Beautiful Soup is used because it provides an easy-to-use interface for parsing HTML/XML documents and extracting data from them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb20608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09526796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "#It provides built-in support for handling HTTP requests and responses,\n",
    "# making it an ideal choice for creating a web interface for a web scraping project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb52e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4247315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a continuous delivery service that automates the software release process for web applications. \\nCodePipeline provides a pipeline for building, testing, and deploying code changes to production environments.\\nIt integrates with other AWS services such as CodeCommit, CodeBuild, CodeDeploy, and Elastic Beanstalk to provide\\na complete end-to-end solution for continuous delivery.  '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "#the aws service used in this project is\"-\n",
    "#1 aws code pipeline\n",
    "#2 elastic beanstalk\n",
    "\n",
    "#elastic beanstalk:-\n",
    "\"\"\" This is a fully managed service that makes it easy to deploy and run applications\n",
    "in various programming languages such as Java, .NET, PHP, Node.js, Python, Ruby, and Go.\n",
    "Elastic Beanstalk provides an environment for running web applications, including servers, databases, and load balancers \"\"\"\n",
    "\n",
    "#code pipline :-\n",
    "\"\"\"This is a continuous delivery service that automates the software release process for web applications. \n",
    "CodePipeline provides a pipeline for building, testing, and deploying code changes to production environments.\n",
    "It integrates with other AWS services such as CodeCommit, CodeBuild, CodeDeploy, and Elastic Beanstalk to provide\n",
    "a complete end-to-end solution for continuous delivery.  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c457385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69fd357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
